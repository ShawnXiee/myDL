终极目的：语义分割

FCN

1.1 before FCN
使用传统特征
sliding window + classifier

1.2 fully convolutinal

same 卷积
加padding 维度保持不变，计算量太大

1.3 FCN 原理：
关键字：
利用已经存在的网络（vgg，resnet）
任意大小的输入
上采样 upsample : 得到和原有图片大小一致的图片，encode
下采样 downsampling: 特征提取 ，decode

传统网络：
尺寸变小，尺寸固定
一般会下采样到1/32

三大核心创新点：

1.卷积化

作用：
固定输入变任意输入
一维输出变二维输出

  convolution:将后面的全连接层也替换层卷积层
  全卷积，full convolution： kernel的的尺寸和输入图片一致，数量为类别目录，
  这样就可以用卷积达到和全连接层一样的效果。

输出：coarse output，粗糙的输出，需要进行上采样
一张图片224×224图片输出为1*1×N，N为类别数目
讲图片变成任意输入时，滑动框每次输入224*224，进行卷积化，达到输出是二维的效果
225*225 则输出为2*2，如果图片小于224，需要进行特殊处理


2.上采样
作用：在卷积化后，图片尺寸发生变化，讲其变成和原图片大小一致。

方法：

unpooling,反池化：记录最大值的位置，反池化的时候将其填充回去，无法完全恢复，只能恢复信号最强的部分

插值,双线性插值
传统的方法，没有进行学习
线性插值： 根据已知的2个点构造线性模型，估计未知点的位置
双线性插值：根据4个点构造模型，估计未知点的位置

装置卷积，transposed convolution 也叫分数卷积fractionally-strided convolution

卷积： patch -> number
转置卷积： number -> patch

卷积的矩阵化：
input： 4×4
kernel： 3×3
ouput： 2*2

等效： output = w × input
w： 4×16
将input变成16×1
讲output变成4*1
 
转置矩阵则为：
input = W × output
W: 16 *4
转置矩阵只能恢复形状，不能恢复数据，数值靠学习
实现：torch.nn.ConvTranspose2d

FCN-32s： 直接上采样32倍，得到原图形大小

3. Skip Architecture

FCN-16s: 先上采样2倍，进行特征融合，再进行16倍上采样

特征融合： 原图像和上采样上来的图像像素相加
上采样保证图片尺寸一致，channel还需要使用1*1卷积进行调整

层次越低，location 信息越多
层次越多，语义信息越多
